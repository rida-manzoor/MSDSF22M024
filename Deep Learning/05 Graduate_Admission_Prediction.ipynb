{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rida-manzoor/DL/blob/main/Graduate_Admission_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyzes admission data where the output variable is the chance of admission.\n",
    "The goal is to predict the chance of admission based on input features using an Artificial Neural Network (ANN).\n",
    "The notebook includes steps such as data loading, preprocessing, model building, training, evaluation, and prediction.\n",
    "The ANN architecture typically consists of input, hidden, and output layers, with appropriate activation functions\n",
    "(e.g., ReLU for hidden layers, softmax for multiclass classification in the output layer), loss function\n",
    "(e.g., mean squared error for regression), and optimizer (e.g., Adam optimizer).\n",
    "Training involves optimizing the model's weights and biases using backpropagation and gradient descent.\n",
    "Evaluation metrics such as mean squared error, accuracy, or other relevant metrics are used to assess the model's performance.\n",
    "The notebook may also include visualization of training/validation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CfnRfkj24wBs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Qnk61x0w5GMs",
    "outputId": "13d6787a-215b-4686-f593-e2cbe19b1603"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "495        332          108                  5  4.5   4.0  9.02         1   \n",
       "496        337          117                  5  5.0   5.0  9.87         1   \n",
       "497        330          120                  5  4.5   5.0  9.56         1   \n",
       "498        312          103                  4  4.0   5.0  8.43         0   \n",
       "499        327          113                  4  4.5   4.5  9.04         0   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "..                ...  \n",
       "495              0.87  \n",
       "496              0.96  \n",
       "497              0.93  \n",
       "498              0.73  \n",
       "499              0.84  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('admission_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EpjqjYJq5Tl_",
    "outputId": "a839d074-edb9-449c-e913-10921ca623fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   GRE Score          500 non-null    int64  \n",
      " 1   TOEFL Score        500 non-null    int64  \n",
      " 2   University Rating  500 non-null    int64  \n",
      " 3   SOP                500 non-null    float64\n",
      " 4   LOR                500 non-null    float64\n",
      " 5   CGPA               500 non-null    float64\n",
      " 6   Research           500 non-null    int64  \n",
      " 7   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 31.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "jQIiSA3B5eCz",
    "outputId": "208eda67-2603-47f3-9aee-5eab0fea7f23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>316.472000</td>\n",
       "      <td>107.192000</td>\n",
       "      <td>3.114000</td>\n",
       "      <td>3.374000</td>\n",
       "      <td>3.48400</td>\n",
       "      <td>8.576440</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.72174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.295148</td>\n",
       "      <td>6.081868</td>\n",
       "      <td>1.143512</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>0.92545</td>\n",
       "      <td>0.604813</td>\n",
       "      <td>0.496884</td>\n",
       "      <td>0.14114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.34000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>8.127500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GRE Score  TOEFL Score  University Rating         SOP       LOR   \\\n",
       "count  500.000000   500.000000         500.000000  500.000000  500.00000   \n",
       "mean   316.472000   107.192000           3.114000    3.374000    3.48400   \n",
       "std     11.295148     6.081868           1.143512    0.991004    0.92545   \n",
       "min    290.000000    92.000000           1.000000    1.000000    1.00000   \n",
       "25%    308.000000   103.000000           2.000000    2.500000    3.00000   \n",
       "50%    317.000000   107.000000           3.000000    3.500000    3.50000   \n",
       "75%    325.000000   112.000000           4.000000    4.000000    4.00000   \n",
       "max    340.000000   120.000000           5.000000    5.000000    5.00000   \n",
       "\n",
       "             CGPA    Research  Chance of Admit   \n",
       "count  500.000000  500.000000         500.00000  \n",
       "mean     8.576440    0.560000           0.72174  \n",
       "std      0.604813    0.496884           0.14114  \n",
       "min      6.800000    0.000000           0.34000  \n",
       "25%      8.127500    0.000000           0.63000  \n",
       "50%      8.560000    1.000000           0.72000  \n",
       "75%      9.040000    1.000000           0.82000  \n",
       "max      9.920000    1.000000           0.97000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zQZN94C45zaB"
   },
   "outputs": [],
   "source": [
    "x = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "S1nbLxSF6R8E",
    "outputId": "73eb3bd9-626d-4664-f2c9-1735ea1267e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hw3I2fcA6U7X"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "453kSqfM7LL5",
    "outputId": "bc7e1c5c-37f4-48b1-8156-bfa221323c69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>325</td>\n",
       "      <td>114</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>320</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>334</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>299</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>312</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>314</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>326</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "243        325          114                  3  3.5   3.0  9.04         1\n",
       "277        320          101                  2  2.5   3.0  8.62         0\n",
       "231        319          106                  3  3.5   2.5  8.33         1\n",
       "361        334          116                  4  4.0   3.5  9.54         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "347        299           94                  1  1.0   1.0  7.34         0\n",
       "458        312          100                  1  3.0   3.0  8.53         1\n",
       "244        314          107                  2  2.5   4.0  8.56         0\n",
       "215        330          116                  5  5.0   4.5  9.36         1\n",
       "104        326          112                  3  3.5   3.0  9.05         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "gfjTk_5t7PTc",
    "outputId": "16813cf7-a454-4e5f-f2e8-2753ec1ff6d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>312</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>317</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>315</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>315</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>339</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>308</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>327</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>332</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>310</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "219        312          104                  3  3.5   3.5  8.42         0\n",
       "103        317          104                  2  4.5   4.0  8.47         0\n",
       "86         315          106                  3  4.5   3.5  8.42         0\n",
       "201        315          110                  2  3.5   3.0  8.46         1\n",
       "330        327          113                  3  3.5   3.0  8.66         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "130        339          114                  5  4.0   4.5  9.76         1\n",
       "278        308          103                  2  3.0   3.5  8.49         0\n",
       "356        327          109                  3  3.5   4.0  8.77         1\n",
       "141        332          118                  2  4.5   3.5  9.36         1\n",
       "238        310          104                  3  2.0   3.5  8.37         0\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2-is_S6S5gda"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import  MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xMrpk84L5rph"
   },
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "c33Wywxc5uc0"
   },
   "outputs": [],
   "source": [
    "x_train_scaled = scalar.fit_transform(x_train)\n",
    "x_test_scaled = scalar.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UIry5xeK66an"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GcNBHJSc7lSK"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qlGJ80H67nVl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\DL0\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# input Layer\n",
    "model.add(Dense(32,activation='relu',input_dim=7))\n",
    "\n",
    "# Two hidden layers, we can have more hidden layers or more neurons. That depends on our understanding.\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7O9Oz3x74pO",
    "outputId": "08ea5a00-e619-4ee2-bbdd-dc486ca98f4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,401</span> (9.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,401\u001b[0m (9.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,401</span> (9.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,401\u001b[0m (9.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZpZe4Fg877_j"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fq7JB5xC8GVA",
    "outputId": "65d313d4-387b-4a65-f5d7-74017044478b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.4621 - val_loss: 0.2414\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1985 - val_loss: 0.0683\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0525 - val_loss: 0.0287\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0280 - val_loss: 0.0334\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0233 - val_loss: 0.0183\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0154 - val_loss: 0.0151\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0079 - val_loss: 0.0089\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0033 - val_loss: 0.0034\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jh4yBUgk8TKH",
    "outputId": "fba56b3d-ec77-4823-96b6-d6636d257703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHFIcEHo8lnG",
    "outputId": "d7520178-68ff-4b9d-c1ee-20ff38ab85b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8099912252326782"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "f8l_XQCS8rnO",
    "outputId": "6bbe648c-48c5-47f2-d2bf-8872def5b086"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a96cd6f8d0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zo26SZej9eoL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMEdEXaemxR2CqwHEpw29Nq",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
