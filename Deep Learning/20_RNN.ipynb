{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuz3nVlUZhHxBt4bDTvNy3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rida-manzoor/DL/blob/main/20_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agenda\n",
        "\n",
        "- Why RNN Needed\n",
        "- RNN vs ANN\n",
        "- Data in RNN\n",
        "- How RNN work?\n",
        "- Forward Propagation in RNN\n",
        "- vectors\n",
        "- Embeddings\n",
        "- Types of RNN\n",
        "- Backpropagation in RNN\n",
        "- Problems with RNN"
      ],
      "metadata": {
        "id": "c4iBucj6ksL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN is the type of sequential model to work on Sequential data."
      ],
      "metadata": {
        "id": "-gqCfHgBk0Dg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why RNN Needed\n",
        "\n",
        "##  Why RNNs are needed: A bullet point breakdown\n",
        "\n",
        "**1. Modeling sequential information:**\n",
        "\n",
        "* **Remember past inputs:** Unlike standard neural networks, RNNs have internal \"memory\" that allows them to retain information from previous inputs. This is crucial for tasks like:\n",
        "    * **Natural Language Processing (NLP):** Analyzing text requires understanding the context of words based on what came before. RNNs are used in machine translation, sentiment analysis, and text generation.\n",
        "    * **Speech Recognition:** Understanding spoken language depends on the sequence of sounds and their context within the sentence.\n",
        "    * **Time Series Forecasting:** Predicting future values in a sequence (stock prices, weather patterns) relies on understanding past trends.\n",
        "\n",
        "**2. Handling variable-length sequences:**\n",
        "\n",
        "* **Flexible input lengths:** Unlike traditional methods that require fixed-length inputs, RNNs can process sequences of any length. This is beneficial for:\n",
        "    * **Video captioning:** Generating descriptions for videos of varying lengths.\n",
        "    * **Music generation:** Creating musical pieces with different durations.\n",
        "    * **Chatbots:** Responding to user queries of varying lengths in a conversation.\n",
        "\n",
        "**3. Dealing with complex relationships:**\n",
        "\n",
        "* **Capturing long-term dependencies:** RNNs can learn complex relationships between elements in a sequence, even if they are far apart. This is useful for:\n",
        "    * **Machine translation:** Capturing long-range grammatical dependencies between words in different languages.\n",
        "    * **Sentiment analysis:** Understanding the overall sentiment of a text, even if positive and negative words are separated by other content.\n",
        "\n",
        "**However, it's important to note:**\n",
        "\n",
        "* **Training challenges:** Standard RNNs can suffer from vanishing gradients, making them difficult to train on long sequences. Variants like LSTMs and GRUs address this issue.\n",
        "* **Computational cost:** RNNs can be computationally expensive to train and run due to their sequential nature.\n",
        "\n",
        "**In conclusion, RNNs are powerful tools for tasks involving sequential data due to their ability to remember past information, handle variable lengths, and learn complex relationships. However, their training challenges and computational cost need to be considered.**"
      ],
      "metadata": {
        "id": "k-uxeOg33HDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANN vs. RNN for NLP tasks\n",
        "\n",
        "**Difficulties of ANNs for NLP:**\n",
        "\n",
        "* **No memory:** ANNs lack internal memory, making it difficult to understand the context of words in a sequence. They struggle with understanding:\n",
        "    * **Sentence structure:** They wouldn't recognize the difference between \"The dog chased the cat\" and \"The cat chased the dog.\"\n",
        "    * **Sentiment:** They might misinterpret sarcasm or irony due to lacking context.\n",
        "\n",
        "**Difficulties with specific NLP tasks:**\n",
        "\n",
        "* **Machine translation:** They wouldn't capture long-range dependencies in grammar and word order between languages.\n",
        "* **Text summarization:** They might miss important points or generate summaries lacking coherence.\n",
        "* **Question answering:** They might miss relevant information spread across the text due to no context memory.\n",
        "\n",
        "**Reasons not to use ANNs for NLP:**\n",
        "\n",
        "* **Limited accuracy:** They often underperform compared to RNNs on NLP tasks.\n",
        "* **Limited flexibility:** They struggle with variable-length input and capturing long-term dependencies.\n",
        "\n",
        "**RNNs to the rescue!**\n",
        "\n",
        "* **Internal memory:** They remember previous words, enabling them to understand context and relationships.\n",
        "* **Flexible input:** They handle different sentence lengths naturally.\n",
        "* **Long-term dependencies:** They capture connections between elements even if distant in the sequence.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7T0JbBoY4th4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data in RNN\n",
        "\n",
        "Data in RNNs is stored in two key ways: **timesteps** and **input features**. Here's a breakdown:\n",
        "\n",
        "**Timesteps:**\n",
        "\n",
        "* Imagine an RNN processing a sentence. Each word in the sentence becomes a **timestep**. The network processes information at each timestep, incorporating it into its internal memory.\n",
        "* Think of it like stepping through the sentence word by word. Each step represents a new timestep with new information.\n",
        "* The number of timesteps depends on the length of the sequence. A short sentence might have 5-10 timesteps, while a long document might have hundreds or even thousands.\n",
        "\n",
        "**Input Features:**\n",
        "\n",
        "* Each timestep doesn't just hold a single word. It also contains information about that word, like its **embedding vector**. This vector represents the word's meaning in a high-dimensional space.\n",
        "* Think of it like capturing various aspects of the word, such as its meaning, part of speech, and relationships with other words.\n",
        "* The number of features depends on the chosen representation (e.g., word embeddings can have hundreds of dimensions).\n",
        "\n",
        "**Combining Timesteps and Features:**\n",
        "\n",
        "* At each timestep, the RNN processes the input features (e.g., embedding vector) and its internal memory (information from previous timesteps).\n",
        "* This processing involves complex calculations using functions like gates and activation functions.\n",
        "* The result of this processing updates the internal memory and can also generate an output (e.g., predict the next word in a sentence).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ig_Q2x9s55Gs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How RNN work?\n",
        "\n",
        "Let's assume we are working on following data\n",
        "\n",
        "|review|Sentiment| RNN Input shape |\n",
        "--------|----|------------|\n",
        "|Movie was good | 1| (3,5)\n",
        "Movie was bad | 0|(3,5)\n",
        "Movie was not good | 0| (4,5)\n",
        "\n",
        "\n",
        "Here in this data we will have 5 vectors.\n",
        "\n",
        "movie → [1,0,0,0,0]\n",
        "\n",
        "was → [0,1,0,0,0]\n",
        "\n",
        "good → [0,0,1,0,0]\n",
        "\n",
        "bad → [0,0,0,1,0]\n",
        "\n",
        "not → [0,0,0,0,1]\n",
        "\n",
        "\n",
        "Here in this data (3,5) means there are 3 time steps and 5 total features.\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "If we are saying our input is 'x'. Then\n",
        "- Row1 will be 'x1'\n",
        "- Row2 will be 'x2'\n",
        "- Row3 will be 'x3'\n",
        "\n",
        "And each input feature will be 'x11'\n",
        "- For row1 (x1)\n",
        "\n",
        "  - Movie → x_11\n",
        "  - was → x_12\n",
        "  - good → x_13\n",
        "\n",
        "- For row2 (x2)\n",
        "  - movie → x_21\n",
        "  - was → x_22\n",
        "  - bad → x_23\n",
        "\n",
        "- For row3 (x3)\n",
        "  - movie → x_31\n",
        "  - was → x_32\n",
        "  - not → x_33\n",
        "  - good → x_34"
      ],
      "metadata": {
        "id": "T3RhotPn67Q-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp3vCb4y7iL9"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dense, SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN Architecture.\n",
        "# one input layer and one hidden layer\n",
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(3,input_shape=(4,5)))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsDQ0a9RLyG_",
        "outputId": "6af91099-0372-4acb-e7b8-110c858cab89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 3)                 27        \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31 (124.00 Byte)\n",
            "Trainable params: 31 (124.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_weights()[0].shape)\n",
        "model.get_weights()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mqqK0XqMS0K",
        "outputId": "4ba65964-33dd-4ebb-aaef-507697efacd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.48703045,  0.3188302 , -0.52045697],\n",
              "       [ 0.388331  , -0.39352322, -0.696949  ],\n",
              "       [-0.42381108, -0.02778387, -0.66490006],\n",
              "       [-0.5465789 ,  0.12045324,  0.08881193],\n",
              "       [-0.46420035,  0.80267555, -0.7627485 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_weights()[1].shape)\n",
        "model.get_weights()[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UAy3MGrMvfj",
        "outputId": "13fc39a3-941d-47d1-e2f7-02296fecc56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.66310775,  0.39399698,  0.6364389 ],\n",
              "       [ 0.05589984,  0.8218182 , -0.567001  ],\n",
              "       [ 0.7464337 , -0.41155964, -0.52292967]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_weights()[2].shape)\n",
        "model.get_weights()[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM6T2ViPM80t",
        "outputId": "765f26bd-ba45-451d-89e2-205606744512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_weights()[3].shape)\n",
        "model.get_weights()[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9ohu8ksM-it",
        "outputId": "f4817565-434e-4db1-afe5-5a4ea5a58045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.2209935 ],\n",
              "       [-0.31076336],\n",
              "       [-1.1767027 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_weights()[4].shape)\n",
        "model.get_weights()[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vru9mZJrNAcS",
        "outputId": "beb45cb8-580b-4514-9339-78e30a4a4c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forward Propagation\n",
        "\n",
        "Forward propagation in a recurrent neural network (RNN) is the process of passing information from the first input to the last output, one step at a time. Here's a breakdown:\n",
        "\n",
        "**1. Setting the Stage:**\n",
        "\n",
        "* Before starting, the RNN's internal memory (hidden state) is initialized with a specific value, usually zeros.\n",
        "* The input sequence is divided into individual elements (words, characters, etc.), each representing a timestep.\n",
        "\n",
        "**2. Processing Each Timestep:**\n",
        "\n",
        "* At each timestep:\n",
        "    * **Combine inputs:** The current input element and the previous hidden state are combined.\n",
        "    * **Activate:** This combined information is passed through an activation function, transforming it into a new value.\n",
        "    * **Update memory:** The resulting value is used to update the RNN's hidden state (internal memory). This captures information from previous steps.\n",
        "    * **Generate output (optional):** Depending on the task, an output might be generated at each timestep based on the current hidden state and input.\n",
        "\n",
        "**3. Moving Forward:**\n",
        "\n",
        "* The updated hidden state becomes the starting point for processing the next timestep.\n",
        "* This process repeats for all timesteps in the sequence.\n",
        "* The final output, if not generated at each step, is usually based on the final hidden state of the sequence.\n",
        "\n",
        "**Here's an analogy:**\n",
        "\n",
        "Imagine you're reading a sentence word by word. Each word is a timestep. You keep track of the previous words' meaning in your mind (similar to the hidden state). As you read each new word, you combine its meaning with what you remember from before and update your understanding of the sentence (similar to updating the hidden state). Finally, you reach the end of the sentence and have a complete understanding (similar to the final output).\n",
        "\n",
        "**Key points to remember:**\n",
        "\n",
        "* Information flows from left to right (or forward) in the network.\n",
        "* The hidden state captures information from previous timesteps, allowing for context-aware processing.\n",
        "* RNNs can be used for tasks requiring sequential data analysis, like text generation, translation, and speech recognition.\n"
      ],
      "metadata": {
        "id": "p9BEDM7BOEHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "s16vODTnNCU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = ['go Pak',\n",
        "        'pak pak',\n",
        "        'hip hip hurray',\n",
        "        'jeety ga bhai koi to jeety ga',\n",
        "        'babar azam',\n",
        "        'deep learning',\n",
        "        'recurrent neural network',\n",
        "        'stucked',\n",
        "        'viral and trendy']"
      ],
      "metadata": {
        "id": "8v0_LultqL8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(oov_token='bad')"
      ],
      "metadata": {
        "id": "QG6ffkHeqppi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(docs)"
      ],
      "metadata": {
        "id": "VgH5fkd9q_02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWhgM8xDrFrE",
        "outputId": "703639dc-b4ff-44d5-d453-843e344c0c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bad': 1,\n",
              " 'pak': 2,\n",
              " 'hip': 3,\n",
              " 'jeety': 4,\n",
              " 'ga': 5,\n",
              " 'go': 6,\n",
              " 'hurray': 7,\n",
              " 'bhai': 8,\n",
              " 'koi': 9,\n",
              " 'to': 10,\n",
              " 'babar': 11,\n",
              " 'azam': 12,\n",
              " 'deep': 13,\n",
              " 'learning': 14,\n",
              " 'recurrent': 15,\n",
              " 'neural': 16,\n",
              " 'network': 17,\n",
              " 'stucked': 18,\n",
              " 'viral': 19,\n",
              " 'and': 20,\n",
              " 'trendy': 21}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfKZU4fbrJfH",
        "outputId": "6fa57c0d-8097-403b-9b90-19158be8b48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('go', 1),\n",
              "             ('pak', 3),\n",
              "             ('hip', 2),\n",
              "             ('hurray', 1),\n",
              "             ('jeety', 2),\n",
              "             ('ga', 2),\n",
              "             ('bhai', 1),\n",
              "             ('koi', 1),\n",
              "             ('to', 1),\n",
              "             ('babar', 1),\n",
              "             ('azam', 1),\n",
              "             ('deep', 1),\n",
              "             ('learning', 1),\n",
              "             ('recurrent', 1),\n",
              "             ('neural', 1),\n",
              "             ('network', 1),\n",
              "             ('stucked', 1),\n",
              "             ('viral', 1),\n",
              "             ('and', 1),\n",
              "             ('trendy', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = tokenizer.texts_to_sequences(docs)\n",
        "sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNjHx-b-rTo1",
        "outputId": "c0e3e4f2-6828-40ef-bca5-fb76cf0e0207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 2],\n",
              " [2, 2],\n",
              " [3, 3, 7],\n",
              " [4, 5, 8, 9, 10, 4, 5],\n",
              " [11, 12],\n",
              " [13, 14],\n",
              " [15, 16, 17],\n",
              " [18],\n",
              " [19, 20, 21]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to keep all sequences of same size we will pad sequences\n",
        "\n",
        "from keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "fgoiPGI5rrns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = pad_sequences(sequence, padding='post')"
      ],
      "metadata": {
        "id": "Jxz11Egor-Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYhbCdJ8sHb-",
        "outputId": "ee1ab58b-92f9-4dc4-d7a0-ee66ce58e1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  2,  0,  0,  0,  0,  0],\n",
              "       [ 2,  2,  0,  0,  0,  0,  0],\n",
              "       [ 3,  3,  7,  0,  0,  0,  0],\n",
              "       [ 4,  5,  8,  9, 10,  4,  5],\n",
              "       [11, 12,  0,  0,  0,  0,  0],\n",
              "       [13, 14,  0,  0,  0,  0,  0],\n",
              "       [15, 16, 17,  0,  0,  0,  0],\n",
              "       [18,  0,  0,  0,  0,  0,  0],\n",
              "       [19, 20, 21,  0,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings\n",
        "\n",
        "In NLP, word embedding is a term used for representation of words for text analysis, typically in the form of real valued vector that encodes the meaning of the word such that the words that are closer in vector space are expected to be similar in meaning.\n",
        "\n",
        "ADvantage\n",
        "- Dense represtation\n",
        "- Can capture semantic meanings"
      ],
      "metadata": {
        "id": "rlj2qHTHsZxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TYpe of RNN\n",
        "\n",
        "- Many to Many\n",
        "- Many to one\n",
        "- Many to Many\n",
        "- One to One"
      ],
      "metadata": {
        "id": "Per65vQCuCKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Many to one\n",
        "- Input should be in sequence (Sentences, characters, time series)\n",
        "- Output will be non-sequential(Scalar value)\n",
        "**Application*\n",
        "    - Sentiment Analysis\n",
        "    - Rating Prediction\n",
        "\n",
        "\n",
        "\n",
        "## One to Many\n",
        "- Input is nonsequential data (img, tabular)\n",
        "- Output will be sequential\n",
        "**Application*\n",
        "    - Image Captioning\n",
        "    - Music Generation\n",
        "\n",
        "## Many to Many\n",
        "- Both input and output data is sequential\n",
        "- Two types\n",
        "    - Same length many to many\n",
        "            - POS tagging\n",
        "            - Named Entity Recognition\n",
        "    - Variable length many to many\n",
        "            - Machine Translation\n",
        "\n",
        "\n",
        "## One to One\n",
        "Not really RNNs\n",
        "\n",
        "- *Application*\n",
        "      - Image classification"
      ],
      "metadata": {
        "id": "W88FV5jtzcme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation through time\n",
        "\n",
        "We suppose we are working with many to one RNN problem. In which we have sentences as input and sentiment as output.\n",
        "\n",
        "\n",
        "| Setences | Sentiments|\n",
        "|-----------|----------|\n",
        "|cat mat rat | 1 |\n",
        "| rat mat cat | 0 |\n",
        "| rat cat mat | 1|\n",
        "\n",
        "- Step 1 : Generate Vocabulary\n",
        "      - cat [1 0 0]\n",
        "      - mat [0 1 0]\n",
        "      - rat [0 0 1]\n",
        "\n",
        "- Step 2: Vectorize data\n",
        "\n",
        "|  | X | Y |\n",
        "|---|---|---|\n",
        "| x_1 | [1 0 0] [0 1 0][0 0 1] | 1\n",
        "| x_2 | [0 0 1][0 1 0][1 0 0] | 0\n",
        "| x_3 | [0 0 1][1 0 0][0 1 0] | 1\n",
        "\n",
        "\n",
        "Let's suppose we have only one hidden layer with 3 neurons. Total weights will be:\n",
        "\n",
        "$w_i = (3x3)$\n",
        "\n",
        "$w_h = (3x3)$\n",
        "\n",
        "$w_0 = (3x1)$\n",
        "\n",
        "$O_1 = f(x_11 w_i + O_0 w_h)$\n",
        "\n",
        "$O_2 = f(x_12 w_i + O_1 w_h)$\n",
        "\n",
        "$O_3 = f(x_13 w_i + O_2 w_h)$\n",
        "\n",
        "$ŷ = σ(O_3 w_0)$\n",
        "\n",
        "Now we will calculate loss:\n",
        "\n",
        "$L = -y_i logŷ_i - (1-y_i)log(1-ŷ_i)$\n",
        "\n",
        "Now we have to minimize loss, we will use gradient descent\n",
        "\n",
        "$w_0 = w_0 -η\\frac{∂L}{∂w_0}$\n",
        "\n",
        "$w_i = w_i -η\\frac{∂L}{∂w_i}$\n",
        "\n",
        "$w_h = w_h -η\\frac{∂L}{∂w_h}$\n",
        "\n",
        "\n",
        "To find these gradient we have all values(initial weights, learning rate) except partial derivatives. SO in next step we will calculate all partial derivatives.\n",
        "\n",
        "\n",
        "$\\frac{∂L}{∂w_0}=\\frac{∂L}{∂ŷ}\\frac{∂ŷ}{∂w_0}$\n",
        "\n",
        "$\\frac{∂L}{∂w_i}=\\frac{∂L}{∂ŷ}\\frac{∂ŷ}{∂O_3}\\frac{∂O_3}{∂w_i} + \\frac{∂L}{∂ŷ}\\frac{∂ŷ}{∂O_3}\\frac{∂O_3}{∂O_2}\\frac{∂O_2}{∂w_i} +  \\frac{∂L}{∂ŷ}\\frac{∂ŷ}{∂O_3}\\frac{∂O_3}{∂O_2}\\frac{∂O_2}{∂O_1}\\frac{∂O_1}{w_i}$\n",
        "\n",
        "$\\frac{∂L}{∂w_i}=\\sum_{j=1}^{3}\\frac{∂L}{∂ŷ}\\frac{∂ŷ}{∂O_j}\\frac{∂O_j}{∂w_i}$\n",
        "\n",
        "\n",
        "$\\frac{∂L}{∂w_h}=\\frac{∂L}{∂ŷ}\\frac{∂ŷ}{∂O_3}\\frac{∂O_3}{∂w_h} + \\frac{∂L}{∂ŷ}\\frac{∂ŷ}{∂O_3}\\frac{∂O_3}{∂O_2}\\frac{∂O_2}{∂w_h} +  \\frac{∂L}{∂ŷ}\\frac{∂ŷ}{∂O_3}\\frac{∂O_3}{∂O_2}\\frac{∂O_2}{∂O_1}\\frac{∂O_1}{w_h}$\n",
        "\n",
        "$\\frac{∂L}{∂w_h}=\\sum_{j=1}^{3}\\frac{∂L}{∂ŷ}\\frac{∂ŷ}{∂O_j}\\frac{∂O_j}{∂w_h}$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qlimPt-E1amU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problems with RNN\n",
        "\n",
        "RNNs are not much used for sequential data because of these two problems:\n",
        "- The problem of long term dependency (vinishing gradient)\n",
        "- The problem of unstable gradients (exploding gradient)"
      ],
      "metadata": {
        "id": "ai3FAhqUT13c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LJ8XJ_g9sJY3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}