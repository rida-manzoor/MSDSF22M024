{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOLib+M5wf8vTULzUv79wM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rida-manzoor/DL/blob/main/Pre_trained_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why use pre-trained models?\n",
        "- When we want to work on classification problem for image classification. We want alot of **Labelled** data.\n",
        "- It will take alot of time to train model.\n",
        "\n",
        "## ImageNet Dataset\n",
        "**Why**\n",
        "-  In the early 2000s, a substantial surge in scientific endeavors was directed towards the development of deep learning models and algorithms. In 2006, Fei Fei Li recognized a pivotal requirement for substantial data in the pursuit of advancing deep learning methodologies. In response to this imperative, Li initiated the construction of an extensive image database encompassing 1.4 million images, spanning across 20,000 distinct categories, all meticulously labeled in a hierarchical manner. Particularly noteworthy was the annotation of one million images with bounding boxes, a crucial aspect employed for object localization purposes. This ambitious undertaking laid a foundational cornerstone in the field, serving as a catalyst for subsequent advancements in deep learning research.\n",
        "\n",
        "\n",
        "### ImageNet Large Scale Visual Recognition Challenge(ILSVRC)\n",
        "- Started in 2010\n",
        "- Goal was to recognize best models\n",
        "- Dataset used for this competition was subset of actual ImageNet database, 1 millions images, and 1000 classes.\n",
        "- 2010 → ML model → 28%\n",
        "- 2011 → ML model → 25%\n",
        "- 2012 → AlexNet → 16.4%. It was the first time when DL model was used in this challenge. Also it was the first time when GPU and ReLu were used.\n",
        "- 2013 → ZFNet → 11.7%\n",
        "- 2014 → VGG → 7.3%\n",
        "- 2015 → GoogleNet → 6.7%\n",
        "- 2016 → ResNet → 3.5%"
      ],
      "metadata": {
        "id": "7RvlGbeqU2xL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NyvJvLfgUHCo"
      },
      "outputs": [],
      "source": [
        "# Keras pre trained models\n",
        "import keras\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(weights='imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngh4LESJafrU",
        "outputId": "35d532bf-6942-4a1f-aa8d-032a36fcb201"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102967424/102967424 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/download (4).jpg'\n",
        "img = keras.utils.load_img(img_path, target_size=(224, 224))\n",
        "x = keras.utils.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)"
      ],
      "metadata": {
        "id": "n65AmQ1sakyB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(x)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQz98uWhanyk",
        "outputId": "73718ddf-74cd-4258-fc4d-3647bee51c3c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 217ms/step\n",
            "Predicted: [('n01514859', 'hen', 0.93280625), ('n01514668', 'cock', 0.05751642), ('n01807496', 'partridge', 0.005558546)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We will try to make ALexNet architecture\n",
        "\n",
        "![a](https://cdn.analyticsvidhya.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-19-16-01-03.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "XCplxTO7btOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "b1fxUD7Xa_n0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "jfXRaynScgHm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Conv2D())"
      ],
      "metadata": {
        "id": "p1MzyVT0dIN7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
