{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rida-manzoor/GenAI/blob/main/5_1_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain_community\n",
        "!pip install -q langchain_objectbox\n",
        "!pip install -q langchain_openai\n",
        "!pip install -q langchain_text_splitter\n",
        "!pip install -q langchain_core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPrZw2NMVtzJ",
        "outputId": "d5f36b32-e3f9-43a1-c5ed-253bcee43344"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.1 requires langchain-core<0.4.0,>=0.3.6, but you have langchain-core 0.1.52 which is incompatible.\n",
            "langchain-community 0.3.1 requires langchain-core<0.4.0,>=0.3.6, but you have langchain-core 0.1.52 which is incompatible.\n",
            "langchain-text-splitters 0.3.0 requires langchain-core<0.4.0,>=0.3.0, but you have langchain-core 0.1.52 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.1/378.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-objectbox 0.1.0 requires langchain-core<0.2.0,>=0.1.45, but you have langchain-core 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement langchain_text_splitter (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for langchain_text_splitter\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSpk7GH8WCWQ",
        "outputId": "374998c7-a0db-497e-d4ae-7ee7c5e27ea7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.0.0-py3-none-any.whl (292 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/292.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m286.7/292.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_icmlDlGVfYZ"
      },
      "outputs": [],
      "source": [
        "## Pdf reader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader=PyPDFLoader('data.pdf')\n",
        "docs=loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBbMX4K-VfYa",
        "outputId": "880ebaf8-4aac-4daa-ae1d-aa488263425b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'data.pdf', 'page': 0}, page_content='The\\nPUCIT\\nDepartment\\nof\\nData\\nScience\\nwas\\nestablished\\non\\nJanuary\\n1st,\\n2021.\\nThe\\nChairman\\nof\\nthe\\nDepartment\\nof\\nData\\nScience\\nis\\nDR.\\nMUHAMMAD\\nKAMRAN\\nMALIK.\\nHe\\nhas\\ndone\\nPhD\\nComputer\\nScience,\\nPU.\\nCurrently,\\ntwo\\nprograms\\nare\\noffered:\\nBS\\nData\\nScience\\nand\\nMPhil\\nData\\nScience.\\nFaculty\\nincludes\\nDr\\nAdnan\\nAbid,\\nDr\\nShahid\\nManzoor,\\nDr\\nMuhammad\\nNadeem\\nMajeed,\\nDr\\nSyed\\nFaisal\\nBukhari,\\nDr\\nKhurram\\nShahzad,\\nand\\nDr\\nMuhammad\\nArif\\nButt.\\nDr.\\nMuhammad\\nArif\\nButt\\nis\\nan\\nAssistant\\nProfessor\\nat\\nthe\\nDepartment\\nof\\nData\\nScience,\\nUniversity\\nof\\nthe\\nPunjab\\n(PU),\\nLahore,\\nPakistan.\\nHe\\nreceived\\nhis\\nMSc\\nand\\nMPhil\\ndegrees\\nboth\\nwith\\na\\nGold\\nMedal\\nfrom\\nPUCIT,\\nUniversity\\nof\\nthe\\nPunjab.\\nDr.\\nButt\\nalso\\nearned\\nhis\\nPh.D.\\nin\\nComputer\\nScience\\nfrom\\nthe\\nsame\\nUniversity.\\nHis\\nresearch\\nfocuses\\non\\napplying\\nfuzzy\\ninference\\nmodels\\nin\\noperating,\\nembedded,\\nand\\ncloud-based\\nsystems/services,\\nwhere\\ndecision-making\\nis\\ninvolved\\nunder\\nimprecise\\nand\\nvague\\nparameters.\\nHis\\nteaching\\ninterests\\nare\\nembedded/real-time\\noperating\\nsystems,\\nsystem\\nprogramming,\\ndata\\nscience\\nand\\nmachine\\nlearning.\\nHis\\nmanagement\\nand\\nteaching\\nexperience\\nspans\\nover\\n33\\nyears\\nin\\nvarious\\nsetups\\nof\\nthe\\nPakistan\\nArmy\\nand\\nat\\nthe\\nUniversity\\nof\\nthe\\nPunjab,\\nLahore,\\nPakistan.\\nHe\\nis\\na\\ndetail-oriented\\nmulti-tasker\\nwith\\nstrong\\norganizational\\nskills,\\nis\\na\\ntactful\\nteam\\nplayer,\\nthrives\\nwithin\\na\\ngroup\\nenvironment\\nand\\nenjoys\\na\\npleasant\\npersonality\\n●\\nDr.\\nMuhammad\\nArif\\nButt\\nis\\nan\\nAssistant\\nProfessor\\nat\\nthe\\nUniversity\\nof\\nthe\\nPunjab,\\nsince\\n2008.\\n●\\nHis\\nacademic,\\nteaching,\\nadministrative\\nand\\nentrepreneurial\\nexperience\\nspans\\nover\\n32\\nyears.\\n●\\nHe\\nhas\\nserved\\nas\\nin\\ncharge/Principal\\nof\\nthe\\nlargest\\nconstituent\\nCollege\\nof\\nthe\\nUniversity\\nof\\nthe\\nPunjab\\nhaving\\n185\\nfaculty\\nand\\nstaff\\nmembers\\nand\\na\\nstudent\\nbody\\nof\\nover\\n2500.\\n●\\nAs\\nChief\\nSecurity\\nOfficer\\nplanned\\nand\\nexecuted\\nsecurity\\nto\\nover\\n45000\\non-campus\\nstudents\\nand\\n7000\\nemployees'),\n",
              " Document(metadata={'source': 'data.pdf', 'page': 1}, page_content='located\\nat\\n5\\ncampuses\\nof\\nthe\\nUniversity\\nhaving\\na\\ntotal\\narea\\nof\\n1800\\nacres.\\n●\\nAnnual\\nfunds\\nmanagement\\nof\\nover\\n300\\nmillion.\\n●\\nCEO\\nof\\na\\nstartup\\nhaving\\n30+\\nemployees\\nand\\ncorporate\\nmanagement\\nof\\nover\\n20\\nmillion\\nper\\nyear.\\n●\\n1st\\nposition\\nand\\nUniversity\\nGold\\nMedal\\nboth\\nin\\nundergraduate\\nand\\ngraduate\\ndegrees.\\n●\\nServed\\nin\\nthe\\nArmed\\nForces\\nof\\nPakistan\\nas\\nan\\nofficer\\nand\\nhas\\nthe\\nhonor\\nof\\nserving\\nas\\nan\\nInstructor\\nat\\nthe\\nSchool\\nof\\nInfantry\\nand\\nTactics\\nQuetta\\n–\\na\\nprestigious\\ntraining\\ninstitute\\nof\\nthe\\nPakistan\\nArmy.')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "docs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uncd0SVyVfYb"
      },
      "source": [
        "## Covert Data into vectorbase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xZ9OGPJLVfYd"
      },
      "outputs": [],
      "source": [
        "from langchain_objectbox.vectorstores import ObjectBox ##vector Database\n",
        "from langchain_openai import OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZlssKndOVfYe"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter()\n",
        "documents = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=userdata.get(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "K1OM7GjyWP9N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A44Q6fgGVfYe",
        "outputId": "a8ebdf21-21fe-40ea-ca84-9bcae907d92e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_objectbox.vectorstores.ObjectBox at 0x7c5c33265270>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "vector = ObjectBox.from_documents(documents, OpenAIEmbeddings(api_key=userdata.get(\"OPENAI_API_KEY\")), embedding_dimensions=768)\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "m5xYqgvmVfYf"
      },
      "outputs": [],
      "source": [
        "# Making rag pipeline\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain import hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv8NnU49VfYg",
        "outputId": "bcd01862-f82d-470b-c95a-d412beec4073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o\", api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAwrK11WVfYg",
        "outputId": "fddce5f0-5a35-420b-ca03-2aeb6c4f37fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "q-pAqamVVfYh"
      },
      "outputs": [],
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm,\n",
        "        retriever=vector.as_retriever(),\n",
        "        chain_type_kwargs={\"prompt\": prompt}\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD6OQwH9VfYi",
        "outputId": "a6796b0a-f8a8-448d-d9c8-99335b917a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-e20883149d51>:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain({\"query\": question })\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'who is arif butt?',\n",
              " 'result': 'Dr. Muhammad Arif Butt is an Assistant Professor at the Department of Data Science, University of the Punjab, Lahore, Pakistan. He has a rich background in academia, research, and administration, with over 32 years of experience, including service in the Pakistan Army. His research focuses on applying fuzzy inference models in systems where decision-making involves imprecise parameters.'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "question = \"who is arif butt?\"\n",
        "result = qa_chain({\"query\": question })\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "2NKzmZavVfYi",
        "outputId": "a13bee3c-85ce-406c-8418-a2e0fefc4fb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dr. Muhammad Arif Butt is an Assistant Professor at the Department of Data Science, University of the Punjab, Lahore, Pakistan. He has a rich background in academia, research, and administration, with over 32 years of experience, including service in the Pakistan Army. His research focuses on applying fuzzy inference models in systems where decision-making involves imprecise parameters.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "result[\"result\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "op9RTisjXarY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lang",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}